---
title: "Peptide Classification with Machine Learning"
subtitle: "BIO512 ML Lab – Encoding peptide features and training classifiers"
author: "Gergely Katona"
date: November 10, 2025
format:
  html:
    theme:
      light: cosmo
      dark: darkly
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: false
---

# Introduction

Protein–protein interactions (PPIs) are central to almost every biological process, yet their complexity often makes them difficult to describe and predict. Traditional models emphasize short-range atomic contacts or electrostatic complementarity, but these approaches can fail to capture the broader physicochemical principles that govern biomolecular recognition.

In the paper “Deciphering peptide–protein interactions via composition-based prediction: a case study with survivin/BIRC5” (Anindya et al., 2024), a different approach was introduced. Instead of focusing on the detailed three-dimensional structures of proteins, the study analyzed their composition (the number and types of atoms or functional groups within peptides) and used this as a predictive descriptor of interaction with the human protein survivin (BIRC5)

The goal of this practical is to build a classifier that predicts peptide binding signal from microarray data using encoded features derived from amino-acid properties. You will first perform a basic run-through of the provided notebook, then complete a set of ML-focused tasks.

Use the annotated notebook aa_scan2_clean_annotated.ipynb for the exercise, it will serve as the hand in for this segment.

::: {.callout-important}
## Create a working directory
```bash
# Create a new folder for this practical
mkdir -p ~/BIO512/Peptide_Classification

# Fetch the required files from Vera
# do note that <__> is a placeholder for your vera username
scp -r <your_vera_username>@vera2.chalmers.se:/cephyr/NOBACKUP/groups/n2bin_gu/BIO512/practicals/Peptide_Classification/* ~/BIO512/Peptide_Classification/
```

- Notebook: aa_scan2_clean_annotated.ipynb
- Property table: aa_properties.xlsx (1,2 and 3 for each encoding)
- Microarray data: Clean_results_2_2019.xlsx

1. Open the notebook in VS Code or Jupyter from your working directory
2. Ensure packages are available: pandas, numpy, seaborn, scikit-learn, matplotlib.

:::

::: {.callout-note}
## Learning Objectives
By the end you should be able to:

- Explain how compositional features can represent molecular information.
- Implement a simple neural network for binary classification in Python.
- Interpret model performance using standard metrics.
- Discuss the implications of composition-based models for molecular biology and drug discovery

:::

---

# Task Overview 

Follow these steps in the notebook. Add short notes under each result.

---

## 1. Data inspection and preparation

- Import core libraries. If an import fails, install and re-run.

```python
import pandas as pd
import seaborn as sns
import matplotlib.pylab as plt
import numpy as np
```

- Load aa_properties.xlsx and confirm it contains the AA letter column (e.g., `aa`) and feature columns. The different numbers (1, 2, 3) correspond to different aa representation schemes.

:::{.callout-note}
The dataset originates from a peptide microarray experiment containing peptides from 36 known or potential survivin interaction partners. Each peptide is 15 amino acids long, with overlapping sequences, and is labeled as binder or non-binder based on fluorescence intensity measurements.
:::

- Load the microarray dataset (Clean_results_2_2019.xlsx)

:::{.callout-important}
### Q1
Look at the distribution of binding and non-binding peptides. How many binders are there? How many non-binders?
:::

---

## 2. Feature encoding

- Represent peptides by counting atomic or functional group.
  - Make sure to check output data from all the matrix transformations so that they make sense.
- Optionally, compare the peptide encodings with the amino acid sequence representations.

---

## 3. Model training
The main engine block of the notebook has multiple configurations of various classifiers prepared. These classifiers all come as part of the [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html) library. To use a different classifier, simply uncomment the relevant line and comment out the rest.

- Begin by building a multilayer perceptron (MLP) classifier using the MLPClassifier from scikit-learn.
- Split the data into training and test sets for model evaluation. If you're interested there are also more advanced methods such as [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)

```python
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn import datasets, svm, metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
#clf = svm.SVC(gamma=0.001)
#clf = RandomForestClassifier(max_depth=None, n_estimators=100, max_features='auto')
#clf = MLPClassifier(solver='lbfgs',random_state=1, max_iter=10000)
clf = MLPClassifier(hidden_layer_sizes=(2,), random_state=1, max_iter=10000)
#clf = GaussianProcessClassifier(1.0 * RBF(1.0))
#clf = DecisionTreeClassifier(max_depth=5)
#clf = KNeighborsClassifier(5)
#clf = AdaBoostClassifier()

feature_names=[u'CA-Gly', u'Pro-MC', u'CB', u'CB-Pro',
        u'Carboxyl', u'Amide',
        u'His', u'Trp', u'Phe-Tyr', u'OH-Tyr', u'CG', u'CD', u'CE',
        u'OH', u'SH', u'S', u'NH3', u'Arg',u'MC']
X = np.array(mergepf[feature_names])

# Other array setups #

Y=np.array(mergepf[u'Fluorescence']>0)

# Other array setups #

sc=StandardScaler()

X_train, X_test, y_train, y_test = train_test_split(
    X, Y, test_size=0.5, shuffle=True)

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

clf.fit(X_train, y_train)
predict=clf.predict(X_test)
predict
```

---

## 4. Model evaluation

- Compute accuracy, precision, recall, and F1 scores.

:::{.callout-important}
### Q2
What are the accuracy, precision, recall, and F1 scores of your MLP? How do these metrics reflect the model's performance?
:::

- Rerun the above section using different encodings.

:::{.callout-important}
### Q3
How do the different encodings affect the model's performance? Which encoding yields the best results?
:::

---

## 5. Visualizing results

- Inspect the trained weights on the neural network

:::{.callout-important}
### Q4
Discuss briefly (1-2 sentences) which peptide compositions are most likely to be classified as survivin binders, and explain how the prediction is determined from the input features, hidden layers, and connection weights of the neural network.
:::

---

## 6. Interpretation and discussion

- Examine feature importance and identify which functional groups most influence binding prediction.

:::{.callout-important}
### Q5
Discuss the implications of your findings. How do the identified features align with known biological principles of peptide binding? What could be the significance to survivin binding in a biological context?
:::

:::{.callout-note}
## Discussion
Answer the following questions with short reflections (2-3 sentences each):

- Why might compositional information alone provide predictive power for peptide binding?

- How do simple models sometimes outperform complex sequence-based neural networks?

- What are the potential advantages and limitations of composition-based approaches in structural biology and drug design?
:::

# Things to append to your submission

- Save your notebook as PRACTICAL_PEPTIDE_CLASSIFICATION_y/n.ipynb
- Add answers to the questions in separate markdown cells
- Add your code blocks from the jupyter notebook with completed code where the placeholders were 
- Include some output cells with figures (if multiple runs are needed, keep only the last one)
- Keep all discussion questions and answers at the end of the notebook in a single markdown cell with 

